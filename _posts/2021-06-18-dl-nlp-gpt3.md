---
layout: post
title:  "GPT3"
subtitle:   "GPT3 review"
categories: dl
tags: nlp
comments: true
---

## 목차
1. GPT3개요
2. Approach
3. 결과
4. References

## 1. GPT3개요

### 1) Introduce
- 기존 Transformer 모델들은 NLP task에 있어서 좋은 퍼포먼스를 보여 주었다.
- 하지만 task마다 매번 fine-tuning을 해야하는 번거로움이 있다.
- GPT3는 <span style="color:blue">**few shot learning**</span>을 통해 이를 해결하려 하였다.
- few shot learning은 다른 예시들을 학습하여 처음보는 문제도 해결하는 방법이다. 
  - fine-tuning없이 좋은 퍼포먼스를 보여 줄 수 있다.
  
### 2) 모델의 장점.
1. 기존 방식에서는 새 태스크를 풀 때마다 fine-tuning을 위해 라벨링된 데이터가 필요했다. 하지만 GPT3는 몇개의 예제들을 이용하여 task에 적용함으로 문법교정, 생성요약, 비평문등 라벨링 데이터를 만들기 어려운 영역을 잘 소화 할 수 있다.

2. fine-tuning은 작은 분포로 재학습 함으로 out-of-distribution에 약하다는 연구 결과가 있다.

3. task마다 매번 fine-tuning을 해야하는 번거로움이 없다.

- 실제사람은 처음보더라도 문장의 패턴을 보고 유연성있게 답변을 한다.

  - 이를 극복하기 위해 **meta-learning** 분야가 연구되었다.

  - 이는 훈련시 다양한 스킬이나 패턴을 인식하는 방법으로 추론시 downstream task에 빠르게 적용하도록 하는 방법이다.

  - GPT-2에서는 이러한 방법을 "in-context learning" 방식으로 진행했는데, 사전학습 모델에 풀고자 하는 태스크를 텍스트 인풋으로 넣는 방식이다.

  - 트랜스 포머를 이용하면 모델 사이즈를 크게 늘릴 수 있고 파라메터 수가 1억 개(GPT-1), 3억 개(BERT), 14억 개(GPT-2), 80억 개(Megatron), 110억 개(T5), 170억 개(Project Turing)까지 늘어나며 다운스트림 태스크에서의 성능은 점점 더 좋아졌다. in-context learning 방식은 최대한 다양한 스킬과 태스크를 모델의 파라메터에 저장해야 하고, 모델의 스케일이 증가할 때 성능이 증가할 가능성이 있다.


## 2. Approach

### 1) 평가방법 
- Fine-Tuning(FT) 
  - 최근에 가장 일반적인 접근법으로, 사전학습된 모델을 원하는 task에 맞도록 감독학습 데이터셋으로 학습시키는 과정을 포함한다. 보통 수천~수만 개의 레이블링된 예시를 필요로 한다.
  
  - 이러한 미세조정(fine-tuning)의 주된 장점은 많은 벤치마크에서 강력한 성능을 가지는 것이다.
  - 주된 단점은 모든 task마다 큰 데이터셋을 새로이 필요로 하며, 분포 외의 데이터에 대해서는 일반화를 잘 못하며, 학습 데이터에 거짓/비논리적인 특성이 있는 경우 이를 흡수할 수도, 사람에 비해 불공정한 비교로 이어질 수도 있다.
  - 이 논문에서는 task-agnostic한 성능을 가지는 것이 목적이기 때문에 GPT-3은 미세조정을 진행하지 않는다. 단, 나중에는 추후 연구로 괜찮은 방향이기에 미세조정을 사용할 수도 있다.

- Few-Shot(FS)
  - 모델이 추론 시간에서 단 몇 개의 예시만을 볼 수 있되 가중치 업데이트는 허용되지 않는 조건이다. 그림 2.1에서 보듯이, 일반적인 데이터셋에서 예시는 문맥과 원하는 답이 있고(예로는 영어-독일어 번역), few-shot은 단 K개의 문맥과 답이 주어진다. 이후 마지막으로 단 한 개의 문맥이 주어지면, 모델은 (정확한) 답을 생성해 내야 한다.
  - 우리는 보통 K는 10~100 정도로 설정했고, 이는 모델의 문맥창(2048)에 잘 맞을만한 개수이다.

  - few-shot의 주된 장점은 task-specific한 데이터에 대한 필요를 크게 줄여주며(즉, 몇 개 없어도 됨) 지나치게 크고 좁은 분포를 갖는 미세조정용 데이터셋을 학습할 가능성을 줄일 수 있다.
  
  - 주된 단점은 이 방법은 미세조정 모델의 SOTA에는 한참 뒤떨어지는 성능을 갖는다는 점이다. 또한, 적은 수라 해도 여전히 task-specific한 데이터를 필요로 한다.
이름에서 알 수 있듯이, 언어 모델에서 few-shot learning은 기계학습에서 다른 문맥에서 사용된 few-shot learning과 연관이 있다 - 둘 다 넓은 분포를 갖는 task에 기반한 학습 방법이며(이 경우에는 사전학습 데이터에서) 새로운 task에 빠르게 적응하는 방법이다.

- One-Shot(IS)
  - few-shot과 비슷하나 단 한 개의 예시와, task에 대한 자연어 지시문이 제공된다는 점이 다르다. 
  - one-shot이 few나 zero-shot과 다른 점은 이 방법이 사람이 소통하는 방법과 가장 흡사한 방법이기 때문이다.
  - 예를 들어, Mechanical Turk와 같이, 사람에게 데이터셋을 만들어내라는 요청을 할 경우, 보통 task에 대해 하나의 예시를 주게 된다(물론 지시문과 함께). 이와 대조적으로, 예시가 아예 없다면 task의 내용이나 형식에 대해 소통하는 것이 어려울 수 있다.
- Zero-Shot(0S)은 one-shot과 비슷하지만 단 하나의 예시도 없으며, 모델은 단지 task에 대한 지시문만을 받는다.
  - 이 방법은 최대의 편의성을 갖는데, robustness나, 거짓 상관관계 등을 걱정할 필요가 없다. 단, 가장 어려운 조건이다.
  - 어떤 경우에는 사람조차도 예시가 없으면 task에 대해 제대로 이해하지 못할 수도 있고, 따라서 이 조건은 “불공정할 정도로 어렵다”고 할 수 있다.
예를 들어, 누군가 ‘200m 달리기를 위한 세계기록 표를 만들라’고 한다면, 이 요청은 상당히 모호할 수 있는데, 표가 어떤 형식을 가져야 하고, 어떤 내용이 들어가야 하는지에 대한 명확한 설명이 없기 때문이다.
  - 그럼에도 불구하고, 적어도 zero-shot의 조건은 사람이 task를 수행하는 것과 가장 가까운 방식이다 - 예로, 아래 그림에서 사람은 단지 텍스트 지시문만을 보고도 무엇을 해야 할지 알 수 있을 것이다.

<p align="center" style="color:gray">
  <img style="margin:50px 0 10px 0" src="https://images.velog.io/images/hanovator/post/e296eb14-e24a-4825-bf50-5c6c146991a9/image.png" alt="" />
</p> 

### 2) Architecture
- pre-training 모델은 GPT-2와 비슷하다.
- modified initialization, pre-normalization, reversable tokenization 적용
- 단, 트랜스포머 레이어의 attention 패턴에 대해 dense와 locally banded sparse attention을 번갈아 사용
- 스케일에 따라 다음과 같이 8가지 모델을 학습하고 테스트 하였다.
- 다만 모델크기를 키우고 데이터의 양과 다양성을 증가시켰으며 훈련기간을 늘렸다.
- learning rate는 모델이 커질수록 오히려 줄였다.
<p align="center" style="color:gray">
  <img style="margin:50px 0 10px 0" src="https://images.velog.io/images/hanovator/post/106f3c69-cfb6-485f-a4c0-71f0eec1408a/image.png" alt="" />
</p> 

### 3) Training Dataset
<p align="center" style="color:gray">
  <img style="margin:50px 0 10px 0" src="https://images.velog.io/images/hanovator/post/9bce888e-f30f-49c8-8409-6203e073721c/image.png" alt="" />
</p> 

## 3. 결과

### 1) 문장완성 태스크에서의 성능
<p align="center" style="color:gray">
  <img style="margin:50px 0 10px 0" src="https://images.velog.io/images/hanovator/post/1add4ed3-b7f7-4679-a1c8-79bf39f496d9/image.png" alt="" />
</p> 

### 2) Closed Book Question Answering
<p align="center" style="color:gray">
  <img style="margin:50px 0 10px 0" src="https://images.velog.io/images/hanovator/post/393c9048-fa08-4f60-83e8-8a95ab2460fa/image.png" alt="" />
</p> 

### 3) Translation
<p align="center" style="color:gray">
  <img style="margin:50px 0 10px 0" src="https://images.velog.io/images/hanovator/post/5f0676ae-5bc0-4f79-9245-a47a84f6e2ad/image.png" alt="" />
</p> 

### 4) Winograd-Style Tasks
- 대명사를 찾는 task
<p align="center" style="color:gray">
  <img style="margin:50px 0 10px 0" src="https://images.velog.io/images/hanovator/post/181bdaa1-e442-49aa-8280-db7479f0d6b1/image.png" alt="" />
</p>

### 5) Common Sense Reasoning
- 기본상식 질문
<p align="center" style="color:gray">
  <img style="margin:50px 0 10px 0" src="https://images.velog.io/images/hanovator/post/53f8e941-8757-49f5-8f6b-1011b3496be6/image.png" alt="" />
</p>

### 6) 기계독해
<p align="center" style="color:gray">
  <img style="margin:50px 0 10px 0" src="https://images.velog.io/images/hanovator/post/9825bb67-2f6a-4bf8-8fc1-44dbe89ceb88/image.png" alt="" />
</p>

### 7) SuperGLUE
<p align="center" style="color:gray">
  <img style="margin:50px 0 10px 0" src="https://images.velog.io/images/hanovator/post/31e4e6bc-cd16-4fde-8cff-ce61c647be8a/image.png" alt="" />
</p>

### 8) 8 NLI (Natural Language Inference)
- 다음 문장을 찾는 task

### 9) Synthetic & Qualitive Tasks
1. 간단한 계산 추론을 하고 특이한 태스크에도 적용할 수 있다는 것을 보이기 위해 실험을 진행했다.

2. Arithmetic
  - 2~5 자릿수 덧셈/ 뺄셈 , 두 자릿수 곱셈, 한 자릿수 복합 연산 태스크에 대해 GPT-3이 이런 문제를 풀 수 있을지 테스트
  - <p align="center" style="color:gray">
  <img style="margin:50px 0 10px 0" src="https://images.velog.io/images/hanovator/post/675eda1f-57dc-4eb4-89a7-83af5c22ecef/image.png" alt="" />
</p>
  
3. Word Scrambling & Manipulation 
  - CL(Cycle letters in word): 순서가 뒤죽박죽 된 단어를 원래로 맞추기
  - <p align="center" style="color:gray">
  <img style="margin:50px 0 10px 0" src="https://images.velog.io/images/hanovator/post/49149310-a2af-474d-8042-4356eca868f2/image.png" alt="" />
</p>

4. SAT analogy
  - <p align="center" style="color:gray">
  <img style="margin:50px 0 10px 0" src="https://images.velog.io/images/hanovator/post/e76fdc58-25ea-4578-8ac8-3234682e0dc1/image.png" alt="" />
</p>

5. 뉴스 기사 생성
  - <p align="center" style="color:gray">
  <img style="margin:50px 0 10px 0" src="https://images.velog.io/images/hanovator/post/949c57b4-6927-477c-9b69-609883c800a1/image.png" alt="" />
</p>

6.  Correcting English Grammar


## 4. References
> - Few-Shot
  - https://www.kakaobrain.com/blog/106
  - https://zzaebok.github.io/machine_learning/FSL
> - Zero-Shot
  - https://arxiv.org/pdf/2011.08641.pdf
> - Paper
  - https://arxiv.org/pdf/2005.14165.pdf
> - gpt3
  -https://greeksharifa.github.io/nlp(natural%20language%20processing)%20/%20rnns/2020/08/14/OpenAI-GPT-3-Language-Models-are-Few-Shot-Learners/





















  


    





















  


    
